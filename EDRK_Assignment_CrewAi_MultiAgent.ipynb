{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp1r4v5lcF0V4SPySOvb5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anirudho747/Edrk_Google-Collab/blob/main/EDRK_Assignment_CrewAi_MultiAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LP1rCcZVwek"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Crew feedback processing pipeline (single-file).\n",
        "\n",
        "\n",
        "- Runtime inputs: OpenAI API key (via getpass) and CSV path (input())\n",
        "- Agents / Tasks included:\n",
        "1) Feedback Analyst (analysis)\n",
        "2) Feedback Categorizer (bug/feature/praise/complaint/spam)\n",
        "3) Technical Extractor (steps, platform, severity, reproducibility, logs, suggested_fix)\n",
        "4) Feature Identifier (feature_summary, demand_score, priority, aggregated_features)\n",
        "5) Ticket Generator (structured tickets + tickets_csv string)\n",
        "6) Ticket Reviewer (reviews generated tickets for completeness & accuracy)\n",
        "\n",
        "\n",
        "- All agents are configured to return JSON only. Nothing is written to disk.\n",
        "- The script runs Crew.kickoff(), then attempts to extract agent outputs (JSON) from the crew result text.\n",
        "- If the ticket reviewer output isn't easily found inside the crew output, the script attempts a best-effort local review using the same LLM instance.\n",
        "\n",
        "\n",
        "Notes:\n",
        "- Do NOT hardcode API keys. Use getpass().\n",
        "- This script attempts robust extraction of JSON-like structures from the crew output; depending on your crewai version output shape, you may need to inspect `result` manually.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Install optional dependency so CrewAI's RAG import doesn't explode\n",
        "!pip install -q --upgrade \\\n",
        "  \"qdrant-client>=1.7.0\" \\\n",
        "  \"crewai>=0.51.0\" \\\n",
        "  \"crewai-tools>=0.11.0\" \\\n",
        "  \"openai>=1.0.0\" \\\n",
        "  pandas duckdb\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================\n",
        "# Installation\n",
        "# ============================================\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Installation complete!\")\n",
        "\n",
        "# ============================================\n",
        "# Import Libraries\n",
        "# ============================================\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "from datetime import datetime, timezone\n",
        "from crewai import Agent, Task, Crew, LLM\n",
        "from crewai_tools import CSVSearchTool\n",
        "import json\n",
        "import re\n",
        "\n",
        "print(\"Libraries imported!\")\n",
        "\n",
        "# ============================================\n",
        "# Setup API Keys\n",
        "# ============================================\n",
        "\n",
        "# Get OpenAI API Key\n",
        "print(\"Enter your OpenAI API Key\")\n",
        "print(\"Get one at: https://platform.openai.com/api-keys\")\n",
        "openai_api_key = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "print(\"API keys configured!\")\n",
        "\n",
        "# ============================================\n",
        "# Configure OpenAI LLM\n",
        "# ============================================\n",
        "\n",
        "# Initialize OpenAI\n",
        "llm = LLM(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    api_key=openai_api_key,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"OpenAI LLM initialized!\")\n",
        "\n",
        "# ============================================\n",
        "# Define Utility Helpers\n",
        "# ============================================\n",
        "\n",
        "def find_json_with_key(text, key):\n",
        "    \"\"\"Find the first JSON object in `text` that contains `key` at top-level.\n",
        "    Returns parsed object or None.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "    # search for {...} blocks\n",
        "    for match in re.finditer(r'\\{[\\s\\S]*?\\}', text, flags=re.DOTALL):\n",
        "        candidate = match.group(0)\n",
        "        try:\n",
        "            parsed = json.loads(candidate)\n",
        "            if isinstance(parsed, dict) and key in parsed:\n",
        "                return parsed\n",
        "        except Exception:\n",
        "            # try fixing single quotes to double quotes\n",
        "            try:\n",
        "                parsed = json.loads(candidate.replace(\"'\", '\"'))\n",
        "                if isinstance(parsed, dict) and key in parsed:\n",
        "                    return parsed\n",
        "            except Exception:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_first_json_array(text):\n",
        "    \"\"\"Find the first JSON array in text and return parsed list or None.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "    for match in re.finditer(r'\\[[\\s\\S]*?\\]', text, flags=re.DOTALL):\n",
        "        candidate = match.group(0)\n",
        "        try:\n",
        "            parsed = json.loads(candidate)\n",
        "            if isinstance(parsed, list):\n",
        "                return parsed\n",
        "        except Exception:\n",
        "            try:\n",
        "                parsed = json.loads(candidate.replace(\"'\", '\"'))\n",
        "                if isinstance(parsed, list):\n",
        "                    return parsed\n",
        "            except Exception:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def safe_print_json(obj, max_items=3):\n",
        "    try:\n",
        "        if isinstance(obj, list):\n",
        "            print(json.dumps(obj[:max_items], indent=2))\n",
        "        else:\n",
        "            print(json.dumps(obj, indent=2))\n",
        "    except Exception:\n",
        "        print(obj)\n",
        "\n",
        "# ============================================\n",
        "# Get CSV File\n",
        "# ============================================\n",
        "\n",
        "# Colab upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "csv_path = next(iter(uploaded.keys()))\n",
        "print(\"CSV uploaded! Path:\", csv_path)  # e.g., 'telecom_feedback_sample (3).csv'\n",
        "\n",
        "# Robust import for CSVSearchTool (different versions export it differently)\n",
        "try:\n",
        "    from crewai_tools import CSVSearchTool\n",
        "except ModuleNotFoundError:\n",
        "    from crewai_tools.tools.csv_search import CSVSearchTool  # fallback\n",
        "\n",
        "# Handle minor constructor differences across versions\n",
        "def make_csv_tool(path: str):\n",
        "    try:\n",
        "        return CSVSearchTool(csv=path)          # common\n",
        "    except TypeError:\n",
        "        try:\n",
        "            return CSVSearchTool(file_path=path)  # variant\n",
        "        except TypeError:\n",
        "            return CSVSearchTool(path=path)       # rare\n",
        "\n",
        "csv_tool = make_csv_tool(csv_path)\n",
        "print(\"CSV tool ready:\", type(csv_tool).__name__)\n",
        "\n",
        "# -------------------------\n",
        "# Agents\n",
        "# -------------------------\n",
        "\n",
        "feedback_analyst = Agent(\n",
        "    role='Feedback Analyst',\n",
        "    goal='Analyze user feedback and extract high-level themes and sentiment.',\n",
        "    backstory='Expert at summarizing user sentiment and surfacing product-level insights.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "feedback_categorizer = Agent(\n",
        "    role='Feedback Categorizer',\n",
        "    goal='Classify feedback rows into bug/feature request/praise/complaint/spam and return structured JSON.',\n",
        "    backstory='NLP classification specialist.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "tech_extractor = Agent(\n",
        "    role='Technical Extractor',\n",
        "    goal='Extract reproducible steps, platform info, severity, reproducibility, logs, and suggested fixes.',\n",
        "    backstory='Engineer-minded extractor.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "feature_identifier = Agent(\n",
        "    role='Feature Identifier',\n",
        "    goal='Detect feature requests, summarize them, and estimate demand and impact.',\n",
        "    backstory='Product-minded agent for feature discovery.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "ticket_generator = Agent(\n",
        "    role='Ticket Generator',\n",
        "    goal='Generate structured tickets for each feedback row and produce CSV text for downstream logging.',\n",
        "    backstory='Agent experienced in converting user reports into tracker tickets with sensible defaults for priority/assignee.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "ticket_reviewer = Agent(\n",
        "    role='Ticket Reviewer',\n",
        "    goal='Review generated tickets for completeness and accuracy and suggest corrections.',\n",
        "    backstory='QA/product-minded reviewer who validates ticket quality for engineering triage.',\n",
        "    tools=[csv_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# Tasks\n",
        "# ============================================\n",
        "\n",
        "# Define a task that utilizes the tool\n",
        "analyze_feedback_task = Task(\n",
        "    description=(\n",
        "        \"Read the provided feedback CSV file, identify common themes, and summarize overall sentiment. \"\n",
        "        \"Return a short JSON report or text summary.\"\n",
        "    ),\n",
        "    expected_output=\"High-level summary JSON or short text.\",\n",
        "    agent=feedback_analyst,\n",
        ")\n",
        "\n",
        "\n",
        "categorize_feedback_task = Task(\n",
        "    description=(\n",
        "        \"For every feedback row in the CSV, classify the entry into exactly one of: bug, feature request, praise, complaint, spam. \"\n",
        "        \"Return a JSON array (one object per row) with fields: row_index, category, confidence (0.0-1.0), notes. JSON only.\"\n",
        "    ),\n",
        "    expected_output='[{\"row_index\":0,\"category\":\"bug\",\"confidence\":0.95,\"notes\":\"\"}, ...]',\n",
        "    agent=feedback_categorizer,          # <-- assign agent\n",
        ")\n",
        "\n",
        "\n",
        "extract_technical_task = Task(\n",
        "    description=(\n",
        "        \"For every feedback row, extract technical details for triage. Return a JSON array one object per row with: \"\n",
        "        \"row_index, steps_to_reproduce (list or null), platform_info (object or null), severity (critical/high/medium/low/unknown), \"\n",
        "        \"reproducibility (always/sometimes/rarely/unknown), logs_snippet (string or null), suggested_fix (string or null), confidence (0.0-1.0), notes. JSON only.\"\n",
        "    ),\n",
        "    expected_output='[...]',\n",
        "    agent=tech_extractor\n",
        ")\n",
        "\n",
        "\n",
        "feature_identify_task = Task(\n",
        "    description=(\n",
        "        \"For every feedback row determine if it is a feature request. Return a JSON object with two keys: 'per_row' (array per input row) and 'aggregated_features'. \"\n",
        "        \"Per-row objects should include: row_index, is_feature_request (true/false), feature_summary (one-line or null), user_impact (high/medium/low/unknown), demand_score (0-100), priority (P0/P1/P2/P3/unknown), rationale, confidence, notes. JSON only.\"\n",
        "    ),\n",
        "    expected_output='{\"per_row\":[...],\"aggregated_features\":[...]}',\n",
        "    agent=feature_identifier,            # <-- assign agent\n",
        ")\n",
        "\n",
        "\n",
        "# Ticket generation task — returns tickets array and tickets_csv string\n",
        "ticket_generation_task = Task(\n",
        "    description=(\n",
        "        \"Generate structured tickets for each feedback row. Return a JSON object with keys 'tickets' (array) and 'tickets_csv' (CSV text string). \"\n",
        "        \"Each ticket must contain: ticket_id (TICKET-{row_index}-{YYYYMMDD}), title, description, reporter_row_index, category, severity, priority, suggested_assignee, tags (array), created_at (UTC ISO), technical_details (object or null), feature_summary (or null), confidence, notes. JSON only.\"\n",
        "    ),\n",
        "    expected_output='{\"tickets\":[...],\"tickets_csv\":\"ticket_id,title,...\\\\n...\"}',\n",
        "    agent=ticket_generator,              # <-- assign agent\n",
        ")\n",
        "\n",
        "\n",
        "# Ticket review task — verifies tickets for completeness & accuracy\n",
        "ticket_review_task = Task(\n",
        "    description=(\n",
        "        \"Review the tickets generated and assess them for completeness and accuracy. Return a JSON array 'reviews' (one object per ticket) with fields: \"\n",
        "        \" - ticket_id, \"\n",
        "        \" - issues (array of strings describing missing/incorrect fields), \"\n",
        "        \" - suggested_corrections (object with corrected fields or guidance), \"\n",
        "        \" - overall_completeness (0.0-1.0), \"\n",
        "        \" - overall_confidence (0.0-1.0), \"\n",
        "        \" - reviewer_notes (short string). \"\n",
        "        \"Rules: check that required fields exist and are consistent (e.g., severity & priority mapping), ensure description includes original feedback and technical summary when applicable, and flag low-confidence tickets (<0.5) for human review. JSON only.\"\n",
        "    ),\n",
        "    expected_output='[{\"ticket_id\":\"TICKET-0-20251021\",\"issues\":[\"missing severity\"],\"suggested_corrections\":{},\"overall_completeness\":0.6,\"overall_confidence\":0.45,\"reviewer_notes\":\"...\"}, ...]',\n",
        "    agent=ticket_reviewer,               # <-- assign agent\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Crew orchestration & kickoff\n",
        "# -------------------------\n",
        "\n",
        "feedback_crew = Crew(\n",
        "    agents=[\n",
        "        feedback_analyst,\n",
        "        feedback_categorizer,\n",
        "        tech_extractor,\n",
        "        feature_identifier,\n",
        "        ticket_generator,\n",
        "        ticket_reviewer\n",
        "    ],\n",
        "    tasks=[\n",
        "        analyze_feedback_task,\n",
        "        categorize_feedback_task,\n",
        "        extract_technical_task,\n",
        "        feature_identify_task,\n",
        "        ticket_generation_task,\n",
        "        ticket_review_task\n",
        "    ],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Kicking off Crew... this will call all agents/tasks (they are instructed to return JSON only).\\n\")\n",
        "result = feedback_crew.kickoff()\n",
        "\n",
        "print(\"\\n--- CREW RAW OUTPUT (truncated preview) ---\\n\")\n",
        "# print a short preview so user knows something ran\n",
        "if isinstance(result, str):\n",
        "    print(result[:1500])\n",
        "else:\n",
        "    try:\n",
        "        print(type(result))\n",
        "        if hasattr(result, 'keys'):\n",
        "            print(list(result.keys())[:10])\n",
        "    except Exception:\n",
        "        print(str(result)[:1000])\n",
        "\n",
        "# -------------------------\n",
        "# Attempt to extract outputs\n",
        "# -------------------------\n",
        "\n",
        "print(\"\\nAttempting to extract generated artifacts from the Crew output...\\n\")\n",
        "\n",
        "# Try to find tickets object (preferred)\n",
        "tickets_obj = None\n",
        "if isinstance(result, dict) and 'tickets' in result:\n",
        "    tickets_obj = result\n",
        "else:\n",
        "    tickets_obj = find_json_with_key(result, 'tickets')\n",
        "\n",
        "if tickets_obj:\n",
        "    print(\"Found tickets object. Sample ticket:\")\n",
        "    try:\n",
        "        print(json.dumps(tickets_obj['tickets'][0], indent=2))\n",
        "    except Exception:\n",
        "        safe_print_json(tickets_obj)\n",
        "else:\n",
        "    print(\"Could not auto-locate a 'tickets' object in the Crew output. You may need to inspect `result` manually.\")\n",
        "\n",
        "# Try to find ticket reviews\n",
        "reviews = None\n",
        "if isinstance(result, dict) and 'reviews' in result:\n",
        "    reviews = result['reviews']\n",
        "else:\n",
        "    reviews = find_json_with_key(result, 'reviews')\n",
        "\n",
        "if reviews:\n",
        "    print(\"Found ticket reviews. Sample:\")\n",
        "    safe_print_json(reviews)\n",
        "else:\n",
        "    print(\"No ticket reviews found automatically. Attempting a best-effort local review if tickets were found...\")\n",
        "\n",
        "# If tickets were found but no reviews, do a local review by prompting the LLM directly (best-effort)\n",
        "if tickets_obj and not reviews:\n",
        "    try:\n",
        "        tickets = tickets_obj.get('tickets') if isinstance(tickets_obj, dict) else None\n",
        "        if isinstance(tickets, list) and len(tickets) > 0:\n",
        "            # build a concise prompt for the LLM\n",
        "            prompt = {\n",
        "                \"instruction\": (\n",
        "                    \"You are a ticket reviewer. Given an array of ticket objects (fields like ticket_id,title,description,category,severity,priority,technical_details,confidence,notes), \"\n",
        "                    \"produce a JSON array 'reviews' (one object per ticket) with fields: ticket_id, issues (array), suggested_corrections (object), overall_completeness (0.0-1.0), overall_confidence (0.0-1.0), reviewer_notes. \"\n",
        "                    \"Be conservative: if confidence<0.5, mark for human review. Return JSON only.\"\n",
        "                ),\n",
        "                \"tickets_sample\": tickets[:5]  # include a small sample to keep prompt size small\n",
        "            }\n",
        "            # Use the same LLM instance to run a quick review\n",
        "            # NOTE: the LLM API here is the Crew LLM wrapper. If Agent.run-like API is available you can call the Agent to run this task.\n",
        "            if hasattr(llm, 'call'):\n",
        "                llm_prompt = (\n",
        "                    f\"INSTRUCTION:\\n{prompt['instruction']}\\n\\nTICKETS_SAMPLE:\\n\"\n",
        "                    f\"{json.dumps(prompt['tickets_sample'], indent=2)}\"\n",
        "                )\n",
        "                llm_response = llm.call(llm_prompt)\n",
        "            else:\n",
        "                llm_response = None\n",
        "\n",
        "            # Try to parse the response\n",
        "            if isinstance(llm_response, str):\n",
        "                parsed = find_json_with_key(llm_response, 'reviews') or find_first_json_array(llm_response)\n",
        "                if parsed:\n",
        "                    print(\"Local LLM review parsed. Sample:\")\n",
        "                    safe_print_json(parsed)\n",
        "                else:\n",
        "                    print(\"Local LLM returned text but we couldn't parse a JSON reviews object/array from it. Inspect the raw response below:\")\n",
        "                    print(llm_response[:2000])\n",
        "            else:\n",
        "                print(\"Could not call LLM for a local review: 'llm.call' not available on LLM wrapper.\\nYou can inspect Crew result manually to find ticket reviewer output.\")\n",
        "        else:\n",
        "            print(\"Tickets object present but empty or not a list; skipping local review.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error while attempting local review:\", str(e))\n",
        "\n",
        "print(\"\\nPipeline finished. Inspect the printed outputs above. If you want strict sequential chaining (categorizer -> extractor -> feature identifier -> ticket generator -> reviewer) where outputs are explicitly passed between agents, say 'implement chaining' and I will provide an orchestrated version.\")"
      ]
    }
  ]
}